{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Introduction to Hypster\n",
                "\n",
                "**`Hypster`** is a lightweight configuration system for AI & Machine Learning projects.\n",
                "It offers minimal, intuitive pythonic syntax, supporting hierarchical and swappable configurations.\n",
                "\n",
                "## Key Benefits\n",
                "\n",
                "- 🐍 Pythonic API for a familiar and expressive logic\n",
                "- ✨ Separating configuration from execution logic for cleaner & modular code\n",
                "- 🦥 \"Lazy\" instantiation for serialization in production settings\n",
                "- 🧹 `Combinations` API for Hyperparameter \"Sweeps\"\n",
                "\n",
                "## Installation\n",
                "\n",
                "You can install Hypster via `pip`:\n",
                "\n",
                "```bash\n",
                "pip install hypster\n",
                "```\n",
                "\n",
                "This will install everything you need to use Hypster in your Python projects.\n",
                "\n",
                "## Basic Usage\n",
                "\n",
                "Let's start with a simple example to demonstrate how Hypster works:"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 12,
            "metadata": {},
            "outputs": [],
            "source": [
                "from hypster import HP, config\n",
                "\n",
                "\n",
                "@config\n",
                "def my_config(hp: HP):\n",
                "    # All imports should be inside the function\n",
                "    import os\n",
                "\n",
                "    chunking_strategy = hp.select([\"paragraph\", \"semantic\", \"fixed\"], default=\"paragraph\")\n",
                "\n",
                "    llm_model = hp.select(\n",
                "        {\"haiku\": \"claude-3-haiku-20240307\", \"sonnet\": \"claude-3-5-sonnet-20240620\", \"gpt-4o-mini\": \"gpt-4o-mini\"},\n",
                "        default=\"gpt-4o-mini\",\n",
                "    )\n",
                "\n",
                "    provider = \"ANTHROPIC\" if llm_model.startswith(\"claude\") else \"OPENAI\"\n",
                "    api_key_exists = f\"{provider}_API_KEY\" in os.environ\n",
                "\n",
                "    llm_config = {\"temperature\": hp.number(0), \"max_tokens\": hp.number(64)}\n",
                "\n",
                "    system_prompt = hp.text(\"You are a helpful assistant. Answer with one word only\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Now we can instantiate the configs with our selections and overrides:"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 13,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/plain": [
                            "{'chunking_strategy': 'paragraph',\n",
                            " 'llm_config': {'temperature': 0, 'max_tokens': 64},\n",
                            " 'llm_model': 'claude-3-haiku-20240307'}"
                        ]
                    },
                    "execution_count": 13,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "results = my_config(\n",
                "    final_vars=[\"chunking_strategy\", \"llm_config\", \"llm_model\"],\n",
                "    selections={\"llm_model\": \"haiku\"},\n",
                "    overrides={\"llm_config.temperature\": 0.5},\n",
                ")  # nested parameter name\n",
                "results"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "In this example:\n",
                "\n",
                "1. We imported `HP` and `config` from Hypster.\n",
                "2. We defined a configuration function decorated with `@config`.\n",
                "3. Inside the function, we used `hp.select`, `hp.number` & `hp.text` to lazily select hyperparameters.\n",
                "4. We instantiated the configuration space and displayed the results."
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "\n",
                "> **Important Note**: All imports must be defined within the function scope in order for Hypster to work correctly. Working this way the allows for easy portability and deployment in different environments."
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "> **Important Note #2**: No return statement is needed for @config functions. I can lazily select the final variables (final_var) when we instantiate our configuration."
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "hypster-env",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.10.14"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 2
}
