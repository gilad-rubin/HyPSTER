{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Combinations API\n",
    "\n",
    "The Combinations API in Hypster allows you to generate and query all possible combinations of hyperparameters in your configuration. This is particularly useful for hyperparameter tuning and exploring different model configurations.\n",
    "\n",
    "## Generating Combinations\n",
    "\n",
    "### Using `get_combinations()`\n",
    "\n",
    "The `get_combinations()` method generates all possible combinations of hyperparameters for a given configuration.\n",
    "\n",
    "Example:\n",
    "\n",
    "```python\n",
    "from hypster import HP, config, save\n",
    "\n",
    "@config\n",
    "def model_config(hp: HP):\n",
    "    model_type = hp.select([\"cnn\", \"rnn\"], default=\"cnn\")\n",
    "    if model_type == \"cnn\":\n",
    "        num_layers = hp.select([3, 5], default=3)\n",
    "    else:\n",
    "        cell_type = hp.select([\"lstm\", \"gru\"], default=\"lstm\")\n",
    "    \n",
    "    learning_rate = hp.number_input(default=0.001)\n",
    "\n",
    "save(model_config, \"model_config.py\")\n",
    "\n",
    "# Generate combinations\n",
    "combinations = model_config.get_combinations()\n",
    "print(combinations)\n",
    "```\n",
    "\n",
    "Output:\n",
    "```python\n",
    "[\n",
    "    {'model_type': 'cnn', 'num_layers': 3, 'learning_rate': 0.001},\n",
    "    {'model_type': 'cnn', 'num_layers': 5, 'learning_rate': 0.001},\n",
    "    {'model_type': 'rnn', 'cell_type': 'lstm', 'learning_rate': 0.001},\n",
    "    {'model_type': 'rnn', 'cell_type': 'gru', 'learning_rate': 0.001}\n",
    "]\n",
    "```\n",
    "\n",
    "### Nested Configurations\n",
    "\n",
    "For nested configurations using `hp.propagate()`, the combinations will include the nested structure:\n",
    "\n",
    "```python\n",
    "@config\n",
    "def training_config(hp: HP):\n",
    "    import hypster\n",
    "    \n",
    "    batch_size = hp.select([32, 64], default=32)\n",
    "    model_config = hypster.load(\"model_config.py\")\n",
    "    model_params = hp.propagate(model_config, name=\"model\")\n",
    "\n",
    "# Generate combinations\n",
    "combinations = training_config.get_combinations()\n",
    "print(combinations)\n",
    "```\n",
    "\n",
    "Output:\n",
    "```python\n",
    "[\n",
    "    {'batch_size': 32, 'model.model_type': 'cnn', 'model.num_layers': 3, 'model.learning_rate': 0.001},\n",
    "    {'batch_size': 32, 'model.model_type': 'cnn', 'model.num_layers': 5, 'model.learning_rate': 0.001},\n",
    "    {'batch_size': 32, 'model.model_type': 'rnn', 'model.cell_type': 'lstm', 'model.learning_rate': 0.001},\n",
    "    {'batch_size': 32, 'model.model_type': 'rnn', 'model.cell_type': 'gru', 'model.learning_rate': 0.001},\n",
    "    {'batch_size': 64, 'model.model_type': 'cnn', 'model.num_layers': 3, 'model.learning_rate': 0.001},\n",
    "    {'batch_size': 64, 'model.model_type': 'cnn', 'model.num_layers': 5, 'model.learning_rate': 0.001},\n",
    "    {'batch_size': 64, 'model.model_type': 'rnn', 'model.cell_type': 'lstm', 'model.learning_rate': 0.001},\n",
    "    {'batch_size': 64, 'model.model_type': 'rnn', 'model.cell_type': 'gru', 'model.learning_rate': 0.001}\n",
    "]\n",
    "```\n",
    "\n",
    "## Querying Combinations\n",
    "\n",
    "The `query_combinations()` function allows you to filter the generated combinations based on specific criteria.\n",
    "\n",
    "### Using `query_combinations()`\n",
    "\n",
    "```python\n",
    "from hypster import query_combinations\n",
    "\n",
    "filtered_combinations = query_combinations(combinations, {\"model.model_type\": \"cnn\"})\n",
    "print(filtered_combinations)\n",
    "```\n",
    "\n",
    "Output:\n",
    "```python\n",
    "[\n",
    "    {'batch_size': 32, 'model.model_type': 'cnn', 'model.num_layers': 3, 'model.learning_rate': 0.001},\n",
    "    {'batch_size': 32, 'model.model_type': 'cnn', 'model.num_layers': 5, 'model.learning_rate': 0.001},\n",
    "    {'batch_size': 64, 'model.model_type': 'cnn', 'model.num_layers': 3, 'model.learning_rate': 0.001},\n",
    "    {'batch_size': 64, 'model.model_type': 'cnn', 'model.num_layers': 5, 'model.learning_rate': 0.001}\n",
    "]\n",
    "```\n",
    "\n",
    "You can use multiple criteria in the query:\n",
    "\n",
    "```python\n",
    "filtered_combinations = query_combinations(combinations, {\"model.model_type\": \"cnn\", \"batch_size\": 64})\n",
    "print(filtered_combinations)\n",
    "```\n",
    "\n",
    "Output:\n",
    "```python\n",
    "[\n",
    "    {'batch_size': 64, 'model.model_type': 'cnn', 'model.num_layers': 3, 'model.learning_rate': 0.001},\n",
    "    {'batch_size': 64, 'model.model_type': 'cnn', 'model.num_layers': 5, 'model.learning_rate': 0.001}\n",
    "]\n",
    "```\n",
    "\n",
    "## Best Practices\n",
    "\n",
    "1. Use `get_combinations()` to explore all possible configurations of your model.\n",
    "2. Leverage `query_combinations()` to filter and focus on specific subsets of configurations.\n",
    "3. When dealing with large configuration spaces, consider using these functions in combination with distributed computing frameworks for efficient hyperparameter tuning.\n",
    "4. Remember that the number of combinations can grow exponentially with the number of hyperparameters. Use conditional hyperparameters (like in the `model_config` example) to keep the combination space manageable.\n",
    "\n",
    "By using the Combinations API, you can systematically explore and experiment with different configurations of your models, leading to more thorough and efficient hyperparameter tuning processes."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
