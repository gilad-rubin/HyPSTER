{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import hypster\n",
    "from hypster import HP\n",
    "\n",
    "\n",
    "@hypster.config\n",
    "def my_config(hp: HP):\n",
    "    var1 = hp.select([\"a\", \"b\"], default=\"b\")\n",
    "    var1 = hp.select([\"b\", \"f\"], default=\"f\")\n",
    "    var2 = hp.select({\"c\": 5, \"d\": 7})  # default=\"d\"\n",
    "\n",
    "    var3 = hp.text_input(\"hello\")\n",
    "    var4 = hp.number_input(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'var1': 'b', 'var2': 'hey there', 'var3': 'hello', 'var4': 5}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_config(selections={\"var1\": \"b\"}, overrides={\"var2\": \"hey there\", \"var4\": 5})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "combinations = my_config.get_combinations()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "defaults = my_config.get_defaults()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'var1': ['b', 'f'], 'var3': ['hello'], 'var4': [10]}"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "defaults"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import hypster\n",
    "from hypster import HP\n",
    "\n",
    "\n",
    "@hypster.config\n",
    "def my_config(hp: HP):\n",
    "    chunking_strategy = hp.select([\"paragraph\", \"semantic\", \"fixed\"], default=\"paragraph\")\n",
    "\n",
    "    llm_model = hp.select(\n",
    "        {\"haiku\": \"claude-3-haiku-20240307\", \"sonnet\": \"claude-3-5-sonnet-20240620\", \"gpt-4o-mini\": \"gpt-4o-mini\"},\n",
    "        default=\"gpt-4o-mini\",\n",
    "    )\n",
    "\n",
    "    llm_config = {\"temperature\": hp.number_input(0), \"max_tokens\": hp.number_input(64)}\n",
    "\n",
    "    system_prompt = hp.text_input(\"You are a helpful assistant. Answer with one word only\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = my_config(\n",
    "    final_vars=[\"chunking_strategy\", \"llm_config\", \"llm_model\"],\n",
    "    selections={\"llm_model\": \"haiku\"},\n",
    "    overrides={\"llm_config.temperature\": 0.5},\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'chunking_strategy': 'paragraph',\n",
       " 'llm_config': {'temperature': 0.5, 'max_tokens': 64},\n",
       " 'llm_model': 'claude-3-haiku-20240307'}"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = my_config(selections={\"a\": \"c\"})  # , overrides={\"c\" : 3, \"d\" : 4})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'chunking_strategy': 'paragraph',\n",
       " 'llm_model': 'gpt-4o-mini',\n",
       " 'llm_config': {'temperature': 0, 'max_tokens': 64},\n",
       " 'system_prompt': 'You are a helpful assistant. Answer with one word only'}"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "hypster.save(my_config, \"my_config.py\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import hypster\n",
    "from hypster import HP\n",
    "\n",
    "\n",
    "@hypster.config\n",
    "def my_config_parent(hp: HP):\n",
    "    import hypster\n",
    "\n",
    "    my_config = hypster.load(\"my_config.py\")\n",
    "    my_conf = hp.propagate(my_config)\n",
    "    a = hp.select([\"a\", \"b\", \"c\"], default=\"a\")\n",
    "    c = hp.select({\"x\": 1, \"y\": 2}, default=\"x\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = my_config_parent(final_vars=[], overrides={\"my_conf.a\": \"44\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'my_config': <hypster.core.Hypster at 0x107382650>,\n",
       " 'my_conf': {'chunking_strategy': 'paragraph',\n",
       "  'llm_model': 'gpt-4o-mini',\n",
       "  'llm_config': {'temperature': 0, 'max_tokens': 64},\n",
       "  'system_prompt': 'You are a helpful assistant. Answer with one word only'},\n",
       " 'a': 'a',\n",
       " 'c': 1}"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "combinations = my_config_parent.get_combinations()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'my_conf': {'chunking_strategy': ['paragraph'],\n",
       "  'llm_model': ['gpt-4o-mini'],\n",
       "  'llm_config.temperature': [0],\n",
       "  'llm_config.max_tokens': [64],\n",
       "  'system_prompt': ['You are a helpful assistant. Answer with one word only']},\n",
       " 'a': ['a'],\n",
       " 'c': ['x']}"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_config_parent.get_defaults()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "hypster.save(my_config, \"my_config.py\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_config = hypster.load(\"my_config.py\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "The following variables specified in final_vars do not exist in the configuration: a",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[19], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[43mloaded_config\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfinal_vars\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43ma\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mselections\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mb\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43my\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moverrides\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43ma\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mc\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/python_workspace/hypster/src/hypster/core.py:67\u001b[0m, in \u001b[0;36mHypster.__call__\u001b[0;34m(self, final_vars, selections, overrides)\u001b[0m\n\u001b[1;32m     55\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     56\u001b[0m \u001b[38;5;124;03mExecute the Hypster instance with given parameters.\u001b[39;00m\n\u001b[1;32m     57\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     64\u001b[0m \u001b[38;5;124;03m    Dict[str, Any]: The execution result.\u001b[39;00m\n\u001b[1;32m     65\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     66\u001b[0m hp \u001b[38;5;241m=\u001b[39m HP(final_vars \u001b[38;5;129;01mor\u001b[39;00m [], selections \u001b[38;5;129;01mor\u001b[39;00m {}, overrides \u001b[38;5;129;01mor\u001b[39;00m {})\n\u001b[0;32m---> 67\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execute_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodified_source\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     68\u001b[0m \u001b[38;5;66;03m# self.config_history.append(hp.get_current_combination())\u001b[39;00m\n\u001b[1;32m     69\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[0;32m~/python_workspace/hypster/src/hypster/core.py:94\u001b[0m, in \u001b[0;36mHypster._execute_function\u001b[0;34m(self, hp, modified_source)\u001b[0m\n\u001b[1;32m     91\u001b[0m exec(function_body, exec_namespace)\n\u001b[1;32m     93\u001b[0m \u001b[38;5;66;03m# Process and filter the results\u001b[39;00m\n\u001b[0;32m---> 94\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_process_results\u001b[49m\u001b[43m(\u001b[49m\u001b[43mexec_namespace\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfinal_vars\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/python_workspace/hypster/src/hypster/core.py:122\u001b[0m, in \u001b[0;36mHypster._process_results\u001b[0;34m(self, namespace, final_vars)\u001b[0m\n\u001b[1;32m    120\u001b[0m     non_existent_vars \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m(final_vars) \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mset\u001b[39m(filtered_locals\u001b[38;5;241m.\u001b[39mkeys())\n\u001b[1;32m    121\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m non_existent_vars:\n\u001b[0;32m--> 122\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    123\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe following variables specified in final_vars \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    124\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdo not exist in the configuration: \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    125\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(non_existent_vars)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    126\u001b[0m         )\n\u001b[1;32m    127\u001b[0m     final_result \u001b[38;5;241m=\u001b[39m {k: filtered_locals[k] \u001b[38;5;28;01mfor\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m final_vars}\n\u001b[1;32m    129\u001b[0m logger\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCaptured locals: \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, filtered_locals)\n",
      "\u001b[0;31mValueError\u001b[0m: The following variables specified in final_vars do not exist in the configuration: a"
     ]
    }
   ],
   "source": [
    "result = loaded_config(final_vars=[\"a\"], selections={\"b\": \"y\"}, overrides={\"a\": \"c\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<hypster.core.Hypster at 0x1ffeab1d210>"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loaded_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'a': 'c'}"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = loaded_config(final_vars=[\"a\"], selections={\"b\": \"y\"}, overrides={\"a\": \"c\"})\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from hypster import hypster\n",
    "\n",
    "\n",
    "@hypster\n",
    "def test(hp):\n",
    "    a = hp.select([\"a\", \"b\", \"c\"], default=\"a\")\n",
    "    b = hp.select({\"a\": \"hello\", \"b\": \"world\"}, default=\"a\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = test(final_vars=[\"a\", \"b\"], selections={\"a\": \"c\"}, overrides={\"b\": \"heyyy\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'a': 'a', 'b': 'hello'}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing configs.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile configs.py\n",
    "from hypster import Select, prep\n",
    "from dataclasses import dataclass\n",
    "\n",
    "\n",
    "class CacheInterface:\n",
    "    pass\n",
    "\n",
    "\n",
    "class DiskCache(CacheInterface):\n",
    "    def __init__(self, path, cache_op: str):\n",
    "        self.path = path\n",
    "        self.cache_op = cache_op\n",
    "\n",
    "\n",
    "class MemoryCache(CacheInterface):\n",
    "    def __init__(self, max_size, cache_op: str):\n",
    "        self.max_size = max_size\n",
    "        self.cache_op = cache_op\n",
    "\n",
    "\n",
    "class SqlCache(CacheInterface):\n",
    "    def __init__(self, conn_str, table):\n",
    "        self.conn_str = conn_str\n",
    "        self.table = table\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class CacheManager:\n",
    "    cache: CacheInterface\n",
    "\n",
    "\n",
    "cache_manager = prep(CacheManager(cache=Select(\"cache\")))  # this can also be None\n",
    "\n",
    "\n",
    "cache_op = \"all\"\n",
    "\n",
    "max_size = 1000\n",
    "cache__mem = prep(MemoryCache(max_size=max_size, cache_op=cache_op))\n",
    "\n",
    "path = \"data/cache\"\n",
    "cache__disk = prep(DiskCache(path=path, cache_op=cache_op))\n",
    "\n",
    "cache__new = prep(SqlCache(conn_str=\"sqlite:///data/cache.db\", table=\"cache\"))\n",
    "\n",
    "\n",
    "class OpenAiDriver:\n",
    "    def __init__(self, model):\n",
    "        self.model = model\n",
    "\n",
    "\n",
    "class AnthropicDriver:\n",
    "    def __init__(self, model):\n",
    "        self.model = model\n",
    "\n",
    "\n",
    "llm_driver = Select(\"llm_driver\")\n",
    "llm_driver__openai = prep(OpenAiDriver(model=\"gpt3.5\"))\n",
    "llm_driver__anthropic = prep(AnthropicDriver(model=\"claude3.5\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import configs\n",
    "\n",
    "from hypster import Builder\n",
    "\n",
    "builder = Builder().with_modules(configs)\n",
    "driver = builder.build()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Configuration tree:\n",
      "└── root (root)\n",
      "    ├── cache_manager (CacheManager)\n",
      "    │   └── cache (Select): cache\n",
      "    │       ├── mem (MemoryCache)\n",
      "    │       │   ├── max_size (reference): 1000\n",
      "    │       │   └── cache_op (reference): all\n",
      "    │       ├── disk (DiskCache)\n",
      "    │       │   ├── path (reference): data/cache\n",
      "    │       │   └── cache_op (reference) [SHARED]\n",
      "    │       └── new (SqlCache)\n",
      "    │           ├── conn_str (value): sqlite:///data/cache.db\n",
      "    │           └── table (value): cache\n",
      "    └── llm_driver (Select): llm_driver\n",
      "        ├── openai (OpenAiDriver)\n",
      "        │   └── model (value): gpt3.5\n",
      "        └── anthropic (AnthropicDriver)\n",
      "            └── model (value) [SHARED]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Visualize configuration tree\n",
    "from hypster import visualize_config_tree\n",
    "\n",
    "print(\"\\nConfiguration tree:\")\n",
    "print(visualize_config_tree(driver.root))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_vars = [\"cache_manager\", \"llm_driver\"]\n",
    "selections = {\"llm_driver\": \"anthropic\", \"cache_manager.cache\": \"disk\"}\n",
    "overrides = {\"llm_driver.anthropic.model\": \"claude3-opus\"}\n",
    "results = driver.instantiate(final_vars, selections, overrides)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'data/cache'"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results[\"cache_manager\"].cache.path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Configuration tree:\n",
      "└── root (root)\n",
      "    ├── cache_manager (CacheManager)\n",
      "    │   └── cache (Select): cache\n",
      "    │       └── disk (DiskCache)\n",
      "    │           ├── path (reference): data/cache\n",
      "    │           └── cache_op (reference): all\n",
      "    ├── llm_driver (Select): llm_driver\n",
      "    │   ├── openai (OpenAiDriver)\n",
      "    │   │   └── model (value): gpt3.5\n",
      "    │   └── anthropic (AnthropicDriver)\n",
      "    │       └── model (value) [SHARED]\n",
      "    ├── mem (MemoryCache)\n",
      "    │   ├── max_size (reference): 1000\n",
      "    │   └── cache_op (reference) [SHARED]\n",
      "    ├── disk (DiskCache) [SHARED]\n",
      "    └── new (SqlCache)\n",
      "        ├── conn_str (value): sqlite:///data/cache.db\n",
      "        └── table (value): cache\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Visualize configuration tree\n",
    "from hypster import visualize_config_tree\n",
    "\n",
    "print(\"\\nConfiguration tree:\")\n",
    "print(visualize_config_tree(driver.root))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
