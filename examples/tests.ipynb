{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Definition\n",
    "The user defines the parameters and variants. These can be hierarchical (nested) and swappable.\n",
    "\n",
    "For each Parameter we have different variants. each has:\n",
    "1. Variant Name\n",
    "1. Variant Value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Instantiation \n",
    "In order to instantiate the parameters - we need to make sure that each parameter that is requested (directly or upstream) has a value.\n",
    "It is possible to select a pre-defined variant for a parameter or to override it with an arbitrary value "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lazy Instantiation\n",
    "1. To have the instantiation in the correct place in the program's execution:\n",
    "    1. Serialization - Serializing/packaging the app with instructions only\n",
    "    1. Performance - Instantiating where it makes more sense in the process. Ideally - in the \"warm up\" phase of the driver\n",
    "    1. Allowing Overriding\n",
    "\n",
    "In general, we want to define the possible in the config instead of the DAG to enable configurable swapping without changing code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Main API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from hypster import lazy, Options, Composer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simple data-types"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. construct a dependency graph \"compose\"\n",
    "1. given final_vars - create a subgraph that contains all the dependent nodes from final_vars\n",
    "1. apply the defaults to all the nodes, if there are\n",
    "1. check for the selections and apply them\n",
    "1. then apply the overrides\n",
    "1. if there are any nodes left that need to be selected (Options) and haven't been - error. otherwise - instantiate.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, the question is how do we define a graph, subgraph, nodes and dependency."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile configs.py\n",
    "from hypster import Options\n",
    "\n",
    "temperature = Options({\"low\" : 0.01, \"medium\" : 0.1, \"high\" : 1.0}, default=\"medium\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import configs\n",
    "from hypster import Composer\n",
    "\n",
    "config = Composer().with_modules(configs).compose()\n",
    "config.instantiate(final_vars=[\"temperature\"], \n",
    "                   selections={\"temperature\" : \"low\"}, \n",
    "                   overrides={})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile configs.py\n",
    "from classes import Thermometer\n",
    "from hypster import Options\n",
    "\n",
    "temperature = Options({\"low\" : 0.01, \"medium\" : 0.1, \"high\" : 1.0}, default=\"medium\")\n",
    "thermometer = Thermometer(temperature=temperature, location=\"home\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import configs\n",
    "from hypster import Composer\n",
    "\n",
    "config = Composer().with_modules(configs).compose()\n",
    "config.instantiate(final_vars=[\"thermometer\"], \n",
    "                   selections={\"thermometer.temperature\" : \"low\"}, \n",
    "                   overrides={})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile configs.py\n",
    "from hypster import Options\n",
    "\n",
    "temperature = Options({\"low\" : 0.01, \"medium\" : 0.1, \"high\" : 1.0}, default=\"medium\")\n",
    "\n",
    "# this is only allowed for strings.\n",
    "llm = Options([\"gpt-4o\", \"gpt-4o-mini\", \"gpt-4\"], default=\"gpt-4o\") \n",
    "# will create the same output as:\n",
    "#llm = Options({\"gpt-4o\":\"gpt-4o\", \"gpt-4o-mini\":\"gpt-4o-mini\", \"gpt-4\":\"gpt-4\"}, default=\"gpt-4o\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import configs\n",
    "from hypster import Composer\n",
    "\n",
    "config = Composer().with_modules(configs).compose()\n",
    "config.instantiate(final_vars=[\"llm\", \"temperature\"], \n",
    "                   selections={\"temperature\" : \"low\"}, \n",
    "                   overrides={\"llm\" : \"gpt-4-turbo\"}) #note that this value is not in the options, but it still works"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Complex data-types (Class, Functions) - Part 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from hypster import lazy, Options\n",
    "\n",
    "#We start with \"lazy(X)\" to prepare the class and defer instantiation\n",
    "OpenAiDriver = lazy(OpenAiDriver)\n",
    "AnthropicDriver = lazy(AnthropicDriver)\n",
    "\n",
    "llm_driver = Options({\"anthropic\" : AnthropicDriver(max_tokens=1000),\n",
    "                      \"openai\" : OpenAiDriver(500)} #argument name (max_tokens) should be inferred from \"lazy()\"}\n",
    "                      ,default=\"anthropic\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = Composer().with_modules(configs).compose()\n",
    "config.instantiate(final_vars=[\"llm_driver\"], \n",
    "                   selections={\"llm_driver\" : \"openai\"}, \n",
    "                   overrides={\"llm_driver.openai.max_tokens\" : 200}) #should also work if max_tokens is defined implicitly"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Complex data-types (Class, Functions) - Part 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile configs.py\n",
    "\n",
    "from hypster import lazy, Options\n",
    "OpenAiDriver = lazy(OpenAiDriver)\n",
    "AnthropicDriver = lazy(AnthropicDriver)\n",
    "\n",
    "llm_driver = OpenAiDriver(model=Options([\"gpt-4o\", \"gpt-4o-mini\", \"gpt-4\"], default=\"gpt-4o\"), \n",
    "                          max_tokens=Options({\"low\" : 200, \"medium\" : 500, \"high\" : 1000}, default=\"medium\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = Composer().with_modules(configs).compose()\n",
    "config.instantiate(final_vars=[\"llm_driver\"], \n",
    "                   selections={}, #takes default values \n",
    "                   overrides={\"llm_driver.max_tokens\" : 300})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Complex data-types (Class, Functions) - Part 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile configs.py\n",
    "\n",
    "from hypster import lazy, Options\n",
    "OpenAiDriver = lazy(OpenAiDriver)\n",
    "AnthropicDriver = lazy(AnthropicDriver)\n",
    "\n",
    "model = Options([\"gpt-4o\", \"gpt-4o-mini\", \"gpt-4\"], default=\"gpt-4o\")\n",
    "llm_driver = OpenAiDriver(model=model, \n",
    "                          max_tokens=Options({\"low\" : 200, \"medium\" : 500, \"high\" : 1000}, default=\"medium\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = Composer().with_modules(x).compose()\n",
    "#These are equivalent:\n",
    "selections={\"model\" : \"gpt-4o-mini\"} #notice that this refers to the variable \"model\"\n",
    "selections={\"llm_driver.model\" : \"gpt-4o-mini\"} #this refers to the argument model of the OpenAiDriver class\n",
    "config.instantiate(final_vars=[\"llm_driver\"], \n",
    "                   selections=selections,\n",
    "                   overrides={\"llm_driver.max_tokens\" : 300})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Complex data-types (Class, Functions) - Part 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "openai_model = Options([\"gpt-4o\", \"gpt-4o-mini\", \"gpt-4\"], default=\"gpt-4o\")\n",
    "llm_driver = OpenAiDriver(model=openai_model, \n",
    "                          max_tokens=Options({\"low\" : 200, \"medium\" : 500, \"high\" : 1000}, default=\"medium\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = Composer().with_modules(x).compose()\n",
    "#These are equivalent:\n",
    "selections={\"openai_model\" : \"gpt-4o-mini\"} #notice that this refers to the variable \"openai_model\"\n",
    "selections={\"llm_driver.model\" : \"gpt-4o-mini\"} #this refers to the argument model of the OpenAiDriver class\n",
    "config.instantiate(final_vars=[\"llm_driver\"], \n",
    "                   selections=selections,\n",
    "                   overrides={\"llm_driver.max_tokens\" : 300})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "openai_model = Options([\"gpt-4o\", \"gpt-4o-mini\", \"gpt-4\"], default=\"gpt-4o\")\n",
    "llm_driver = OpenAiDriver(model=openai_model, \n",
    "                          max_tokens=Options({\"low\" : 200, \"medium\" : 500, \"high\" : 1000}, default=\"medium\"))\n",
    "tabular_driver = OpenAiDriver(model=openai_model, max_tokens=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = Composer().with_modules(configs).compose()\n",
    "config.instantiate(final_vars=[\"llm_driver\"], \n",
    "                   selections={\"openai_model\" : \"gpt-4o-mini\"},\n",
    "                   overrides={\"llm_driver.model\" : \"gpt-4o\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm_driver = OpenAiDriver(Options([\"gpt-4o\", \"gpt-4o-mini\", \"gpt-4\"], default=\"gpt-4o\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = Composer().with_modules(configs).compose()\n",
    "config.instantiate(final_vars=[\"llm_driver\"], \n",
    "                   selections={\"llm_driver.model\" : \"gpt-4o-mini\"},\n",
    "                   overrides={\"llm_driver.max_tokens\" : 300})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# so the hypster variable name is defined either by the variable name itself (openai_model = ...)\n",
    "# in this case - it'll affect all the classes/functions that use this variable\n",
    "# if it is \"selected\" or \"overrided\" as llm_driver.model - it'll only affect the OpenAiDriver class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "openai_model = Options([\"gpt-4o\", \"gpt-4o-mini\", \"gpt-4\"], default=\"gpt-4o\")\n",
    "llm_driver = OpenAiDriver(model=openai_model, \n",
    "                          max_tokens=Options({\"low\" : 200, \"medium\" : 500, \"high\" : 1000}, default=\"medium\"))\n",
    "tabular_driver = OpenAiDriver(model=openai_model, max_tokens=1500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = Composer().with_modules(x).compose()\n",
    "#These are equivalent:\n",
    "selections={\"openai_model\" : \"gpt-4o-mini\"} #will affect llm_driver and tabular_driver\n",
    "selections={\"llm_driver.model\" : \"gpt-4o-mini\"} #will only affect llm_driver and tabular_driver will get the default value\n",
    "config.instantiate(final_vars=[\"llm_driver\"], \n",
    "                   selections=selections,\n",
    "                   overrides={\"llm_driver.max_tokens\" : 300})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'CacheManager' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m cache_manager \u001b[38;5;241m=\u001b[39m \u001b[43mCacheManager\u001b[49m(cache\u001b[38;5;241m=\u001b[39mDiskCache(path\u001b[38;5;241m=\u001b[39mOptions([\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/tmp\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/var/tmp\u001b[39m\u001b[38;5;124m\"\u001b[39m], default\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/tmp\u001b[39m\u001b[38;5;124m\"\u001b[39m)))\n",
      "\u001b[1;31mNameError\u001b[0m: name 'CacheManager' is not defined"
     ]
    }
   ],
   "source": [
    "cache_manager = CacheManager(cache=DiskCache(path=Options([\"/tmp\", \"/var/tmp\"], default=\"/tmp\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sql_cache = SqlCache(table=\"cache\")\n",
    "disk_cache = DiskCache(path=Options([\"/tmp\", \"/var/tmp\"], default=\"/tmp\"))\n",
    "cache_manager = CacheManager(cache=Options([disk_cache, sql_cache])) #this should work and make variant names according to the variable names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import configs\n",
    "from hypster import Composer\n",
    "config = Composer().with_modules(configs).compose()\n",
    "\n",
    "config.instantiate(final_vars=[\"cache_manager\"], \n",
    "                   selections={\"cache\" : \"disk_cache\"},\n",
    "                   overrides={\"disk_cache.path\" : \"new/path\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cache__a = \"gpt-4o\"\n",
    "cache__b = \"gpt-4o-mini\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cache = Param(\"cache\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#does order matter? do variants need to be defined before their Param?\n",
    "#what if there are multiple Params with the same name?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cache = Options([...])\n",
    "cache = Options({...})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# eventualy I want to have a structure that has variant_name & variant value\n",
    "# be careful of circular dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# eventualy eventually (!) I want to populate all the placeholders in the dependency chain\n",
    "# either by selecting a variant or by overriding with a value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cache_manager = CacheManager(cache=cache, when=\"all\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cache_manager = CacheManager(cache=cache, when=\"all\", dest=SqlDest(Credentials(key=\"...\"))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Select"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. simple\n",
    "1. iterable (list, dict, tuple, general iterable?)\n",
    "1. class\n",
    "1. function\n",
    "1. Hypster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cache.select(\"a\")\n",
    "# --> \"gpt-4o\"\n",
    "# does it update cache inplace? does it keep the rest of the variants? \n",
    "# can I do cache.selct(\"b\") afterwards?\n",
    "cache.select(\"a\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pdf-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
