{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Definition\n",
    "The user defines the parameters and variants. These can be hierarchical (nested) and swappable.\n",
    "\n",
    "For each Parameter we have different variants. each has:\n",
    "1. Variant Name\n",
    "1. Variant Value"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Instantiation \n",
    "In order to instantiate the parameters - we need to make sure that each parameter that is requested (directly or upstream) has a value.\n",
    "It is possible to select a pre-defined variant for a parameter or to override it with an arbitrary value "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lazy Instantiation\n",
    "1. To have the instantiation in the correct place in the program's execution:\n",
    "    1. Serialization - Serializing/packaging the app with instructions only\n",
    "    1. Performance - Instantiating where it makes more sense in the process. Ideally - in the \"warm up\" phase of the driver\n",
    "    1. Allowing Overriding\n",
    "\n",
    "In general, we want to define the possible in the config instead of the DAG to enable configurable swapping without changing code"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Main API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from hypster import lazy, Options, Composer"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simple data-types"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. construct a dependency graph \"compose\"\n",
    "1. given final_vars - create a subgraph that contains all the dependent nodes from final_vars\n",
    "1. apply the defaults to all the nodes, if there are\n",
    "1. check for the selections and apply them\n",
    "1. then apply the overrides\n",
    "1. if there are any nodes left that need to be selected (Options) and haven't been - error. otherwise - instantiate.\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, the question is how do we define a graph, subgraph, nodes and dependency."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing configs.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile configs.py\n",
    "from hypster import Options\n",
    "\n",
    "temperature = Options({\"low\" : 0.01, \"medium\" : 0.1, \"high\" : 1.0}, default=\"medium\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'temperature': 0.01}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import configs\n",
    "from hypster import Composer\n",
    "\n",
    "config = Composer().with_modules(configs).compose()\n",
    "config.instantiate(final_vars=[\"temperature\"], \n",
    "                   selections={\"temperature\" : \"low\"}, \n",
    "                   overrides={})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/giladrubin/python_workspace/hypster'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "os.chdir(\"..\")\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting configs.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile configs.py\n",
    "from tests.classes import Thermometer\n",
    "from hypster import lazy, Options\n",
    "\n",
    "thermometer = Thermometer(temperature=Options({\"low\" : 0.01, \"medium\" : 0.1, \"high\" : 1.0}, default=\"medium\"), location=\"home\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "from typing import Any, Dict, List\n",
    "from hypster import Options\n",
    "\n",
    "def instantiate(config_module, vars: List[str], selections: Dict[str, str] = None):\n",
    "    print(f\"DEBUG: Starting instantiation with vars: {vars}, selections: {selections}\")\n",
    "    result = {}\n",
    "    selections = selections or {}\n",
    "\n",
    "    for var_name in vars:\n",
    "        print(f\"DEBUG: Processing variable: {var_name}\")\n",
    "        if not hasattr(config_module, var_name):\n",
    "            raise ValueError(f\"Variable '{var_name}' not found in the config module\")\n",
    "\n",
    "        obj = getattr(config_module, var_name)\n",
    "        print(f\"DEBUG: Original object: {obj}\")\n",
    "        new_obj = _recreate_object(obj, selections, prefix=var_name)\n",
    "        print(f\"DEBUG: Recreated object: {new_obj}\")\n",
    "        result[var_name] = new_obj\n",
    "\n",
    "    return result\n",
    "\n",
    "def _recreate_object(obj: Any, selections: Dict[str, str], prefix: str = \"\"):\n",
    "    print(f\"DEBUG: Recreating object with prefix: {prefix}, type: {type(obj)}\")\n",
    "    \n",
    "    if isinstance(obj, Options):\n",
    "        print(f\"DEBUG: Found Options object: {obj.options}\")\n",
    "        full_path = prefix\n",
    "        selected_option = selections.get(full_path, obj.default)\n",
    "        print(f\"DEBUG: Selected option: {selected_option}\")\n",
    "        return obj.options[selected_option]\n",
    "\n",
    "    if isinstance(obj, dict):\n",
    "        print(f\"DEBUG: Processing dictionary: {obj}\")\n",
    "        return {k: _recreate_object(v, selections, f\"{prefix}.{k}\" if prefix else k) for k, v in obj.items()}\n",
    "\n",
    "    if isinstance(obj, (list, tuple)):\n",
    "        print(f\"DEBUG: Processing list/tuple: {obj}\")\n",
    "        return type(obj)(_recreate_object(item, selections, f\"{prefix}[{i}]\") for i, item in enumerate(obj))\n",
    "\n",
    "    if isinstance(obj, type) or type(obj).__module__ == 'builtins':\n",
    "        print(f\"DEBUG: Skipping built-in or type object: {obj}\")\n",
    "        return obj\n",
    "\n",
    "    if hasattr(obj, '__dict__'):\n",
    "        print(f\"DEBUG: Processing object with __dict__: {obj.__dict__}\")\n",
    "        new_obj = copy.copy(obj)  # Use shallow copy\n",
    "        for attr_name, attr_value in obj.__dict__.items():\n",
    "            new_path = f\"{prefix}.{attr_name}\" if prefix else attr_name\n",
    "            print(f\"DEBUG: Processing attribute: {new_path}\")\n",
    "            new_value = _recreate_object(attr_value, selections, new_path)\n",
    "            setattr(new_obj, attr_name, new_value)\n",
    "        return new_obj\n",
    "\n",
    "    print(f\"DEBUG: Returning object as-is: {obj}\")\n",
    "    return obj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG: Starting instantiation with vars: ['thermometer'], selections: {'thermometer.temperature': 'low'}\n",
      "DEBUG: Processing variable: thermometer\n",
      "DEBUG: Original object: <tests.classes.Thermometer object at 0x11238fdf0>\n",
      "DEBUG: Recreating object with prefix: thermometer, type: <class 'tests.classes.Thermometer'>\n",
      "DEBUG: Processing object with __dict__: {'temperature': <hypster.variables.Options object at 0x11238c160>, 'location': 'home'}\n",
      "DEBUG: Processing attribute: thermometer.temperature\n",
      "DEBUG: Recreating object with prefix: thermometer.temperature, type: <class 'hypster.variables.Options'>\n",
      "DEBUG: Found Options object: {'low': 0.01, 'medium': 0.1, 'high': 1.0}\n",
      "DEBUG: Selected option: low\n",
      "DEBUG: Processing attribute: thermometer.location\n",
      "DEBUG: Recreating object with prefix: thermometer.location, type: <class 'str'>\n",
      "DEBUG: Skipping built-in or type object: home\n",
      "DEBUG: Recreated object: <tests.classes.Thermometer object at 0x117c498a0>\n"
     ]
    }
   ],
   "source": [
    "# Usage example\n",
    "import configs\n",
    "result = instantiate(configs, [\"thermometer\"], selections={\"thermometer.temperature\": \"low\"})\n",
    "result[\"thermometer\"].temperature\n",
    "assert result[\"thermometer\"].temperature == 0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 4\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mconfigs\u001b[39;00m\n\u001b[1;32m      3\u001b[0m result \u001b[39m=\u001b[39m instantiate(configs, \u001b[39mvars\u001b[39m\u001b[39m=\u001b[39m[\u001b[39m\"\u001b[39m\u001b[39mthermometer\u001b[39m\u001b[39m\"\u001b[39m], selections\u001b[39m=\u001b[39m{\u001b[39m\"\u001b[39m\u001b[39mtemperature\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39m\"\u001b[39m\u001b[39mlow\u001b[39m\u001b[39m\"\u001b[39m})\n\u001b[0;32m----> 4\u001b[0m \u001b[39massert\u001b[39;00m result[\u001b[39m\"\u001b[39m\u001b[39mthermometer\u001b[39m\u001b[39m\"\u001b[39m]\u001b[39m.\u001b[39mtemperature \u001b[39m==\u001b[39m \u001b[39m0.01\u001b[39m\n",
      "\u001b[0;31mAssertionError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Usage example\n",
    "import configs\n",
    "result = instantiate(configs, vars=[\"thermometer\"], selections={\"temperature\": \"low\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<hypster.variables.Options at 0x117befbe0>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result[\"thermometer\"].temperature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert result[\"thermometer\"].temperature == 0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import configs\n",
    "from hypster import Composer\n",
    "\n",
    "config = Composer().with_modules(configs).compose()\n",
    "res = config.instantiate(final_vars=[\"thermometer\"], \n",
    "                         selections={\"thermometer.temperature\" : \"low\"}, \n",
    "                         overrides={})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.01"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res[\"thermometer\"].temperature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile configs.py\n",
    "from hypster import Options\n",
    "\n",
    "temperature = Options({\"low\" : 0.01, \"medium\" : 0.1, \"high\" : 1.0}, default=\"medium\")\n",
    "\n",
    "# this is only allowed for strings.\n",
    "llm = Options([\"gpt-4o\", \"gpt-4o-mini\", \"gpt-4\"], default=\"gpt-4o\") \n",
    "# will create the same output as:\n",
    "#llm = Options({\"gpt-4o\":\"gpt-4o\", \"gpt-4o-mini\":\"gpt-4o-mini\", \"gpt-4\":\"gpt-4\"}, default=\"gpt-4o\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import configs\n",
    "from hypster import Composer\n",
    "\n",
    "config = Composer().with_modules(configs).compose()\n",
    "config.instantiate(final_vars=[\"llm\", \"temperature\"], \n",
    "                   selections={\"temperature\" : \"low\"}, \n",
    "                   overrides={\"llm\" : \"gpt-4-turbo\"}) #note that this value is not in the options, but it still works"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Complex data-types (Class, Functions) - Part 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from hypster import lazy, Options\n",
    "\n",
    "#We start with \"lazy(X)\" to prepare the class and defer instantiation\n",
    "OpenAiDriver = lazy(OpenAiDriver)\n",
    "AnthropicDriver = lazy(AnthropicDriver)\n",
    "\n",
    "llm_driver = Options({\"anthropic\" : AnthropicDriver(max_tokens=1000),\n",
    "                      \"openai\" : OpenAiDriver(500)} #argument name (max_tokens) should be inferred from \"lazy()\"}\n",
    "                      ,default=\"anthropic\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = Composer().with_modules(configs).compose()\n",
    "config.instantiate(final_vars=[\"llm_driver\"], \n",
    "                   selections={\"llm_driver\" : \"openai\"}, \n",
    "                   overrides={\"llm_driver.openai.max_tokens\" : 200}) #should also work if max_tokens is defined implicitly"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Complex data-types (Class, Functions) - Part 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile configs.py\n",
    "\n",
    "from hypster import lazy, Options\n",
    "OpenAiDriver = lazy(OpenAiDriver)\n",
    "AnthropicDriver = lazy(AnthropicDriver)\n",
    "\n",
    "llm_driver = OpenAiDriver(model=Options([\"gpt-4o\", \"gpt-4o-mini\", \"gpt-4\"], default=\"gpt-4o\"), \n",
    "                          max_tokens=Options({\"low\" : 200, \"medium\" : 500, \"high\" : 1000}, default=\"medium\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = Composer().with_modules(configs).compose()\n",
    "config.instantiate(final_vars=[\"llm_driver\"], \n",
    "                   selections={}, #takes default values \n",
    "                   overrides={\"llm_driver.max_tokens\" : 300})"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Complex data-types (Class, Functions) - Part 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile configs.py\n",
    "\n",
    "from hypster import lazy, Options\n",
    "OpenAiDriver = lazy(OpenAiDriver)\n",
    "AnthropicDriver = lazy(AnthropicDriver)\n",
    "\n",
    "model = Options([\"gpt-4o\", \"gpt-4o-mini\", \"gpt-4\"], default=\"gpt-4o\")\n",
    "llm_driver = OpenAiDriver(model=model, \n",
    "                          max_tokens=Options({\"low\" : 200, \"medium\" : 500, \"high\" : 1000}, default=\"medium\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = Composer().with_modules(x).compose()\n",
    "#These are equivalent:\n",
    "selections={\"model\" : \"gpt-4o-mini\"} #notice that this refers to the variable \"model\"\n",
    "selections={\"llm_driver.model\" : \"gpt-4o-mini\"} #this refers to the argument model of the OpenAiDriver class\n",
    "config.instantiate(final_vars=[\"llm_driver\"], \n",
    "                   selections=selections,\n",
    "                   overrides={\"llm_driver.max_tokens\" : 300})"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Complex data-types (Class, Functions) - Part 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "openai_model = Options([\"gpt-4o\", \"gpt-4o-mini\", \"gpt-4\"], default=\"gpt-4o\")\n",
    "llm_driver = OpenAiDriver(model=openai_model, \n",
    "                          max_tokens=Options({\"low\" : 200, \"medium\" : 500, \"high\" : 1000}, default=\"medium\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = Composer().with_modules(x).compose()\n",
    "#These are equivalent:\n",
    "selections={\"openai_model\" : \"gpt-4o-mini\"} #notice that this refers to the variable \"openai_model\"\n",
    "selections={\"llm_driver.model\" : \"gpt-4o-mini\"} #this refers to the argument model of the OpenAiDriver class\n",
    "config.instantiate(final_vars=[\"llm_driver\"], \n",
    "                   selections=selections,\n",
    "                   overrides={\"llm_driver.max_tokens\" : 300})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "openai_model = Options([\"gpt-4o\", \"gpt-4o-mini\", \"gpt-4\"], default=\"gpt-4o\")\n",
    "llm_driver = OpenAiDriver(model=openai_model, \n",
    "                          max_tokens=Options({\"low\" : 200, \"medium\" : 500, \"high\" : 1000}, default=\"medium\"))\n",
    "tabular_driver = OpenAiDriver(model=openai_model, max_tokens=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = Composer().with_modules(configs).compose()\n",
    "config.instantiate(final_vars=[\"llm_driver\"], \n",
    "                   selections={\"openai_model\" : \"gpt-4o-mini\"},\n",
    "                   overrides={\"llm_driver.model\" : \"gpt-4o\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm_driver = OpenAiDriver(Options([\"gpt-4o\", \"gpt-4o-mini\", \"gpt-4\"], default=\"gpt-4o\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = Composer().with_modules(configs).compose()\n",
    "config.instantiate(final_vars=[\"llm_driver\"], \n",
    "                   selections={\"llm_driver.model\" : \"gpt-4o-mini\"},\n",
    "                   overrides={\"llm_driver.max_tokens\" : 300})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# so the hypster variable name is defined either by the variable name itself (openai_model = ...)\n",
    "# in this case - it'll affect all the classes/functions that use this variable\n",
    "# if it is \"selected\" or \"overrided\" as llm_driver.model - it'll only affect the OpenAiDriver class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "openai_model = Options([\"gpt-4o\", \"gpt-4o-mini\", \"gpt-4\"], default=\"gpt-4o\")\n",
    "llm_driver = OpenAiDriver(model=openai_model, \n",
    "                          max_tokens=Options({\"low\" : 200, \"medium\" : 500, \"high\" : 1000}, default=\"medium\"))\n",
    "tabular_driver = OpenAiDriver(model=openai_model, max_tokens=1500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = Composer().with_modules(x).compose()\n",
    "#These are equivalent:\n",
    "selections={\"openai_model\" : \"gpt-4o-mini\"} #will affect llm_driver and tabular_driver\n",
    "selections={\"llm_driver.model\" : \"gpt-4o-mini\"} #will only affect llm_driver and tabular_driver will get the default value\n",
    "config.instantiate(final_vars=[\"llm_driver\"], \n",
    "                   selections=selections,\n",
    "                   overrides={\"llm_driver.max_tokens\" : 300})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'CacheManager' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m cache_manager \u001b[38;5;241m=\u001b[39m \u001b[43mCacheManager\u001b[49m(cache\u001b[38;5;241m=\u001b[39mDiskCache(path\u001b[38;5;241m=\u001b[39mOptions([\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/tmp\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/var/tmp\u001b[39m\u001b[38;5;124m\"\u001b[39m], default\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/tmp\u001b[39m\u001b[38;5;124m\"\u001b[39m)))\n",
      "\u001b[1;31mNameError\u001b[0m: name 'CacheManager' is not defined"
     ]
    }
   ],
   "source": [
    "cache_manager = CacheManager(cache=DiskCache(path=Options([\"/tmp\", \"/var/tmp\"], default=\"/tmp\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sql_cache = SqlCache(table=\"cache\")\n",
    "disk_cache = DiskCache(path=Options([\"/tmp\", \"/var/tmp\"], default=\"/tmp\"))\n",
    "cache_manager = CacheManager(cache=Options([disk_cache, sql_cache])) #this should work and make variant names according to the variable names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import configs\n",
    "from hypster import Composer\n",
    "config = Composer().with_modules(configs).compose()\n",
    "\n",
    "config.instantiate(final_vars=[\"cache_manager\"], \n",
    "                   selections={\"cache\" : \"disk_cache\"},\n",
    "                   overrides={\"disk_cache.path\" : \"new/path\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cache__a = \"gpt-4o\"\n",
    "cache__b = \"gpt-4o-mini\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cache = Param(\"cache\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#does order matter? do variants need to be defined before their Param?\n",
    "#what if there are multiple Params with the same name?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cache = Options([...])\n",
    "cache = Options({...})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# eventualy I want to have a structure that has variant_name & variant value\n",
    "# be careful of circular dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# eventualy eventually (!) I want to populate all the placeholders in the dependency chain\n",
    "# either by selecting a variant or by overriding with a value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cache_manager = CacheManager(cache=cache, when=\"all\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cache_manager = CacheManager(cache=cache, when=\"all\", dest=SqlDest(Credentials(key=\"...\"))))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Select"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. simple\n",
    "1. iterable (list, dict, tuple, general iterable?)\n",
    "1. class\n",
    "1. function\n",
    "1. Hypster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cache.select(\"a\")\n",
    "# --> \"gpt-4o\"\n",
    "# does it update cache inplace? does it keep the rest of the variants? \n",
    "# can I do cache.selct(\"b\") afterwards?\n",
    "cache.select(\"a\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pdf-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
