{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "# handle names for expressions - change expression names within expression\n",
    "# go over classes and find invalid assumptions"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "#hypster prepare\n",
    "#Check if any parameter is HpExpression. if not: return the original object\n",
    "#If there is an HpExpression in it\n",
    "    #Save the original call for class/function\n",
    "    #Save args and kwargs as separate dicts"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "import fastai2\n",
    "from fastai2.tabular.all import *\n",
    "from fastai2.metrics import *"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from copy import deepcopy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import optuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 42"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HyPSTER Classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from inspect import signature, Parameter\n",
    "import functools\n",
    "\n",
    "def auto_assign(func):\n",
    "    # Signature:\n",
    "    sig = signature(func)\n",
    "    for name, param in sig.parameters.items():\n",
    "        if param.kind in (Parameter.VAR_POSITIONAL, Parameter.VAR_KEYWORD):\n",
    "            raise RuntimeError('Unable to auto assign if *args or **kwargs in signature.')\n",
    "    # Wrapper:\n",
    "    @functools.wraps(func)\n",
    "    def wrapper(self, *args, **kwargs):\n",
    "        for i, (name, param) in enumerate(sig.parameters.items()):\n",
    "            # Skip 'self' param:\n",
    "            if i == 0: continue\n",
    "            # Search value in args, kwargs or defaults:\n",
    "            if i - 1 < len(args):\n",
    "                val = args[i - 1]\n",
    "            elif name in kwargs:\n",
    "                val = kwargs[name]\n",
    "            else:\n",
    "                val = param.default\n",
    "            setattr(self, name, val)\n",
    "        func(self, *args, **kwargs)\n",
    "    return wrapper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_hp(hp, trial): return hp if not isinstance(hp, HpExpression) else hp.sample(trial)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class HpExpression(object):\n",
    "    def __init__(self, exp1, exp2):\n",
    "        self.exp1 = exp1; self.exp2 = exp2    \n",
    "    \n",
    "    def sample(self, trial): raise NotImplementedError\n",
    "    \n",
    "    def get_name(self):\n",
    "        if self.name is not None: return self.name\n",
    "\n",
    "        name = \"\"\n",
    "        if self.exp1 is not None and isinstance(self.exp1, HpExpression) and hasattr(self.exp1, \"name\"):\n",
    "            name += self.exp1.name\n",
    "        if self.exp2 is not None and isinstance(self.exp2, HpExpression) and hasattr(self.exp2, \"name\"):\n",
    "            if len(name) > 0:\n",
    "                name +=  \"_\"\n",
    "            name += self.exp2.name\n",
    "        self.name = name\n",
    "        return self.name\n",
    "        #TODO: refactor\n",
    "        \n",
    "    def __add__(self, other):  return AddExpression(self, other)\n",
    "    def __radd__(self, other): return AddExpression(other, self)\n",
    "    def __sub__(self, other):  return SubExpression(self, other)\n",
    "    def __rsub__(self, other): return SubExpression(other, self)\n",
    "    def __mul__(self, other):  return MulExpression(self, other)\n",
    "    def __rmul__(self, other): return MulExpression(other, self)\n",
    "    def __div__(self, other):  return DivExpression(self, other)\n",
    "    def __rdiv__(self, other): return DivExpression(other, self)\n",
    "    def __pow__(self, other):  return PowExpression(self, other)\n",
    "    def __rpow__(self, other): return PowExpression(other, self)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SubExpression(HpExpression):\n",
    "    def sample(self, trial):\n",
    "        exp1 = sample_hp(self.exp1, trial)\n",
    "        exp2 = sample_hp(self.exp2, trial)\n",
    "        return exp1 - exp2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AddExpression(HpExpression):    \n",
    "    def sample(self, trial):\n",
    "        exp1 = sample_hp(self.exp1, trial)\n",
    "        exp2 = sample_hp(self.exp2, trial)\n",
    "        return exp1 + exp2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MulExpression(HpExpression):    \n",
    "    def sample(self, trial):\n",
    "        exp1 = sample_hp(self.exp1, trial)\n",
    "        exp2 = sample_hp(self.exp2, trial)\n",
    "        return exp1 * exp2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DivExpression(HpExpression):    \n",
    "    def sample(self, trial):\n",
    "        exp1 = sample_hp(self.exp1, trial)\n",
    "        exp2 = sample_hp(self.exp2, trial)\n",
    "        return exp1 / exp2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PowExpression(HpExpression):    \n",
    "    def sample(self, trial):\n",
    "        exp1 = sample_hp(self.exp1, trial)\n",
    "        exp2 = sample_hp(self.exp2, trial)\n",
    "        return exp1 ** exp2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO: add round, int, floor etc...\n",
    "#TODO: add Brackets () etc...?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "class HpFloat(HpExpression):\n",
    "    @auto_assign\n",
    "    def __init__(self, name, low, high, log=False, step=None):\n",
    "        self.result = None\n",
    "        #TODO: check what's up with log and step\n",
    "        #TODO: move result to HpExpression?\n",
    "        \n",
    "    def sample(self, trial): \n",
    "        self.result = ifnone(self.result, trial.suggest_float(self.name, self.low, self.high))\n",
    "        return self.result\n",
    "    \n",
    "    #TODO: warn if log=True & step is not None\n",
    "    #TODO: check what is the \"*\" in the function definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "class HpInt(HpExpression):\n",
    "    @auto_assign\n",
    "    def __init__(self, name, low, high, step=1):\n",
    "        self.result = None\n",
    "    \n",
    "    def sample(self, trial):\n",
    "        self.result = ifnone(self.result, trial.suggest_int(self.name, self.low, self.high, self.step))\n",
    "        return self.result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "class HpCategorical(HpExpression):\n",
    "    @auto_assign\n",
    "    def __init__(self, name, choices): \n",
    "        self.result = None\n",
    "    \n",
    "    def sample(self, trial): \n",
    "        if self.result is not None:\n",
    "            return self.result\n",
    "        \n",
    "        choices           = self.choices\n",
    "        name              = self.name\n",
    "        optuna_valid_cats = [\"str\", \"int\", \"float\", \"bool\"] #TODO: add more + move to global area\n",
    "        \n",
    "        if any([type(choice) not in optuna_valid_cats for choice in self.choices]):\n",
    "            self.items_names      = [choice.__name__ for choice in choices]\n",
    "            self.dict_items_names = dict(zip(self.items_names, choices))\n",
    "            chosen_hp             = trial.suggest_categorical(name, self.dict_keys)\n",
    "            self.result           = self.dict_items[chosen_hp]\n",
    "            #TODO: add items dict\n",
    "            #TODO: add check for \"choice.__name__\"\n",
    "        else:\n",
    "            self.result = trial.suggest_categorical(name, choices)\n",
    "        return self.result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "class HpList(HpExpression):\n",
    "    @auto_assign\n",
    "    def __init__(self, name, min_len, max_len, hp, same_value=False): pass        \n",
    "    \n",
    "    def sample(self, trial):\n",
    "        lst_len = trial.suggest_int(self.name, self.min_len, self.max_len)\n",
    "        lst = []\n",
    "        if (self.same_value) or (not isinstance(self.hp, HpExpression)):\n",
    "            lst = [sample_hp(self.hp, trial)] * lst_len\n",
    "        else:\n",
    "            for i in range(lst_len):\n",
    "                hp = deepcopy(self.hp)\n",
    "                hp.result = None\n",
    "                hp.name = f\"{hp.get_name()}_{i+1}\"\n",
    "                result = sample_hp(hp, trial)\n",
    "                lst.append(result)\n",
    "                #TODO keep self.result?\n",
    "        return lst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "class HpIterable(HpExpression):\n",
    "    def __init__(self, name, iterable): \n",
    "        self.name = name\n",
    "        self.iterable = iterable\n",
    "\n",
    "    def _sample_list(self, trial, lst):  return [sample_hp(item, trial) for item in lst]\n",
    "    def _sample_dict(self, trial, dct):  return {key : sample_hp(value, trial) for key, value in dct.items()}\n",
    "    def _sample_tuple(self, trial, tup): return (*self._sample_list(trial, tup), )\n",
    "    def _sample_L(self, trial, l):       return L(self._sample_list(trial, l))\n",
    "    \n",
    "    def sample(self, trial):\n",
    "        if   isinstance(self.iterable, dict):   return self._sample_dict(trial, self.iterable)\n",
    "        elif isinstance(self.iterable, list):   return self._sample_list(trial, self.iterable)\n",
    "        elif isinstance(self.iterable, L):      return self._sample_L(trial, self.iterable)\n",
    "        elif isinstance(self.iterable, tuple):  return self._sample_tuple(trial, self.iterable)\n",
    "        else:                                   print(\"Error: unknown Iterable!\")\n",
    "        return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "class HpBool(HpCategorical):\n",
    "    def __init__(self, name):\n",
    "        super().__init__(name, choices=[False, True])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "class HpToggle(HpBool):\n",
    "    def __init__(self, hp): return\n",
    "    def sample(self, trial): return trial.suggest_categorical(f\"toggle_{hp.name}\", [False, True]) \n",
    "    #TODO: fix hp.name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = HpInt(\"start_mom\", 2, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = HpInt(\"layer_size\", 50, 300, 50)\n",
    "y = HpBool(\"booli!\")\n",
    "x = HpList(\"n_layers\", 1, 5, y, same_value=False)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "y = x ** 2"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "start_mom = HpFloat(\"start_mom\", 1.0, 2.0)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "start_mom"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "y = start_mom + 1"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "x = 0.1 - start_mom"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "x = HpIterable(\"hello\", (start_mom, start_mom - 0.1))\n",
    "#x = HpIterable(\"hello\", [start_mom, 4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "optuna.logging.set_verbosity(0)\n",
    "pruner = optuna.pruners.NopPruner()\n",
    "study = optuna.create_study(direction=\"maximize\", pruner=pruner)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(trial):\n",
    "    print(x.sample(trial))\n",
    "    #print(y.sample(trial))\n",
    "    return 1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[W 2020-04-28 21:54:02,598] Setting status of trial#0 as TrialState.FAIL because of the following error: AttributeError(\"'bool' object has no attribute '__name__'\")\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/giladrubin/anaconda3/lib/python3.7/site-packages/optuna/study.py\", line 677, in _run_trial\n",
      "    result = func(trial)\n",
      "  File \"<ipython-input-30-7889c85e27c8>\", line 2, in objective\n",
      "    print(x.sample(trial))\n",
      "  File \"<ipython-input-23-363f3472c934>\", line 15, in sample\n",
      "    result = sample_hp(hp, trial)\n",
      "  File \"<ipython-input-12-79d0fd047f55>\", line 1, in sample_hp\n",
      "    def sample_hp(hp, trial): return hp if not isinstance(hp, HpExpression) else hp.sample(trial)\n",
      "  File \"<ipython-input-22-f3f1fb5fce54>\", line 15, in sample\n",
      "    self.items_names      = [choice.__name__ for choice in choices]\n",
      "  File \"<ipython-input-22-f3f1fb5fce54>\", line 15, in <listcomp>\n",
      "    self.items_names      = [choice.__name__ for choice in choices]\n",
      "AttributeError: 'bool' object has no attribute '__name__'\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'bool' object has no attribute '__name__'",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mAttributeError\u001B[0m                            Traceback (most recent call last)",
      "\u001B[0;32m<ipython-input-31-42dc4570563a>\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[0;32m----> 1\u001B[0;31m \u001B[0mstudy\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0moptimize\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mobjective\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mn_trials\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;36m5\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mtimeout\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;36m600\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m      2\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/anaconda3/lib/python3.7/site-packages/optuna/study.py\u001B[0m in \u001B[0;36moptimize\u001B[0;34m(self, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001B[0m\n\u001B[1;32m    329\u001B[0m             \u001B[0;32mif\u001B[0m \u001B[0mn_jobs\u001B[0m \u001B[0;34m==\u001B[0m \u001B[0;36m1\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    330\u001B[0m                 self._optimize_sequential(\n\u001B[0;32m--> 331\u001B[0;31m                     \u001B[0mfunc\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mn_trials\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mtimeout\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mcatch\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mcallbacks\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mgc_after_trial\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;32mNone\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    332\u001B[0m                 )\n\u001B[1;32m    333\u001B[0m             \u001B[0;32melse\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/anaconda3/lib/python3.7/site-packages/optuna/study.py\u001B[0m in \u001B[0;36m_optimize_sequential\u001B[0;34m(self, func, n_trials, timeout, catch, callbacks, gc_after_trial, time_start)\u001B[0m\n\u001B[1;32m    624\u001B[0m                     \u001B[0;32mbreak\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    625\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 626\u001B[0;31m             \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_run_trial_and_callbacks\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mfunc\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mcatch\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mcallbacks\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mgc_after_trial\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    627\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    628\u001B[0m             \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_progress_bar\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mupdate\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mdatetime\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mdatetime\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mnow\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m \u001B[0;34m-\u001B[0m \u001B[0mtime_start\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mtotal_seconds\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/anaconda3/lib/python3.7/site-packages/optuna/study.py\u001B[0m in \u001B[0;36m_run_trial_and_callbacks\u001B[0;34m(self, func, catch, callbacks, gc_after_trial)\u001B[0m\n\u001B[1;32m    654\u001B[0m         \u001B[0;31m# type: (...) -> None\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    655\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 656\u001B[0;31m         \u001B[0mtrial\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_run_trial\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mfunc\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mcatch\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mgc_after_trial\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    657\u001B[0m         \u001B[0;32mif\u001B[0m \u001B[0mcallbacks\u001B[0m \u001B[0;32mis\u001B[0m \u001B[0;32mnot\u001B[0m \u001B[0;32mNone\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    658\u001B[0m             \u001B[0mfrozen_trial\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_storage\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mget_trial\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mtrial\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_trial_id\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/anaconda3/lib/python3.7/site-packages/optuna/study.py\u001B[0m in \u001B[0;36m_run_trial\u001B[0;34m(self, func, catch, gc_after_trial)\u001B[0m\n\u001B[1;32m    675\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    676\u001B[0m         \u001B[0;32mtry\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 677\u001B[0;31m             \u001B[0mresult\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mfunc\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mtrial\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    678\u001B[0m         \u001B[0;32mexcept\u001B[0m \u001B[0mexceptions\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mTrialPruned\u001B[0m \u001B[0;32mas\u001B[0m \u001B[0me\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    679\u001B[0m             message = \"Setting status of trial#{} as {}. {}\".format(\n",
      "\u001B[0;32m<ipython-input-30-7889c85e27c8>\u001B[0m in \u001B[0;36mobjective\u001B[0;34m(trial)\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[0;32mdef\u001B[0m \u001B[0mobjective\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mtrial\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m----> 2\u001B[0;31m     \u001B[0mprint\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mx\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0msample\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mtrial\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m      3\u001B[0m     \u001B[0;31m#print(y.sample(trial))\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      4\u001B[0m     \u001B[0;32mreturn\u001B[0m \u001B[0;36m1.0\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      5\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m<ipython-input-23-363f3472c934>\u001B[0m in \u001B[0;36msample\u001B[0;34m(self, trial)\u001B[0m\n\u001B[1;32m     13\u001B[0m                 \u001B[0mhp\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mresult\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0;32mNone\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     14\u001B[0m                 \u001B[0mhp\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mname\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0;34mf\"{hp.get_name()}_{i+1}\"\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 15\u001B[0;31m                 \u001B[0mresult\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0msample_hp\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mhp\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mtrial\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     16\u001B[0m                 \u001B[0mlst\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mappend\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mresult\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     17\u001B[0m                 \u001B[0;31m#TODO keep self.result?\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m<ipython-input-12-79d0fd047f55>\u001B[0m in \u001B[0;36msample_hp\u001B[0;34m(hp, trial)\u001B[0m\n\u001B[0;32m----> 1\u001B[0;31m \u001B[0;32mdef\u001B[0m \u001B[0msample_hp\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mhp\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mtrial\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m \u001B[0;32mreturn\u001B[0m \u001B[0mhp\u001B[0m \u001B[0;32mif\u001B[0m \u001B[0;32mnot\u001B[0m \u001B[0misinstance\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mhp\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mHpExpression\u001B[0m\u001B[0;34m)\u001B[0m \u001B[0;32melse\u001B[0m \u001B[0mhp\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0msample\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mtrial\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m      2\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m<ipython-input-22-f3f1fb5fce54>\u001B[0m in \u001B[0;36msample\u001B[0;34m(self, trial)\u001B[0m\n\u001B[1;32m     13\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     14\u001B[0m         \u001B[0;32mif\u001B[0m \u001B[0many\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0mtype\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mchoice\u001B[0m\u001B[0;34m)\u001B[0m \u001B[0;32mnot\u001B[0m \u001B[0;32min\u001B[0m \u001B[0moptuna_valid_cats\u001B[0m \u001B[0;32mfor\u001B[0m \u001B[0mchoice\u001B[0m \u001B[0;32min\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mchoices\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 15\u001B[0;31m             \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mitems_names\u001B[0m      \u001B[0;34m=\u001B[0m \u001B[0;34m[\u001B[0m\u001B[0mchoice\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m__name__\u001B[0m \u001B[0;32mfor\u001B[0m \u001B[0mchoice\u001B[0m \u001B[0;32min\u001B[0m \u001B[0mchoices\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     16\u001B[0m             \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mdict_items_names\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mdict\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mzip\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mitems_names\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mchoices\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     17\u001B[0m             \u001B[0mchosen_hp\u001B[0m             \u001B[0;34m=\u001B[0m \u001B[0mtrial\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0msuggest_categorical\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mname\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mdict_keys\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m<ipython-input-22-f3f1fb5fce54>\u001B[0m in \u001B[0;36m<listcomp>\u001B[0;34m(.0)\u001B[0m\n\u001B[1;32m     13\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     14\u001B[0m         \u001B[0;32mif\u001B[0m \u001B[0many\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0mtype\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mchoice\u001B[0m\u001B[0;34m)\u001B[0m \u001B[0;32mnot\u001B[0m \u001B[0;32min\u001B[0m \u001B[0moptuna_valid_cats\u001B[0m \u001B[0;32mfor\u001B[0m \u001B[0mchoice\u001B[0m \u001B[0;32min\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mchoices\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 15\u001B[0;31m             \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mitems_names\u001B[0m      \u001B[0;34m=\u001B[0m \u001B[0;34m[\u001B[0m\u001B[0mchoice\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m__name__\u001B[0m \u001B[0;32mfor\u001B[0m \u001B[0mchoice\u001B[0m \u001B[0;32min\u001B[0m \u001B[0mchoices\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     16\u001B[0m             \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mdict_items_names\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mdict\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mzip\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mitems_names\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mchoices\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     17\u001B[0m             \u001B[0mchosen_hp\u001B[0m             \u001B[0;34m=\u001B[0m \u001B[0mtrial\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0msuggest_categorical\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mname\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mdict_keys\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;31mAttributeError\u001B[0m: 'bool' object has no attribute '__name__'"
     ]
    }
   ],
   "source": [
    "study.optimize(objective, n_trials=5, timeout=600)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'study' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "\u001B[0;32m<ipython-input-3-cebd4df5353b>\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[0;32m----> 1\u001B[0;31m \u001B[0mstudy\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mtrials_dataframe\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m      2\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;31mNameError\u001B[0m: name 'study' is not defined"
     ]
    }
   ],
   "source": [
    "study.trials_dataframe()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "#TODO consider adding \"name\" into HpExpression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "#HpFunc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "#HpTuple (like list)\n",
    "#HpIterable (?)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "#TODO: support expressions like 5 * HpInt(...)\n",
    "#TODO: support expressions like HpInt(...) * HpFloat(...)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "path = untar_data(URLs.ADULT_SAMPLE)\n",
    "path.ls()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(path/'adult.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "df = df.sample(frac=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "cat_names = ['workclass', 'education', 'marital-status', 'occupation', 'relationship', 'race']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "cont_names = ['age', 'fnlwgt', 'education-num']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "dep_var = \"salary\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "train_df, test_df = train_test_split(df, test_size=0.6, \n",
    "                                     random_state=SEED, \n",
    "                                     stratify=df[dep_var])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "cat = Categorify()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "imp = FillMissing(fill_strategy=FillStrategy.mode, \n",
    "                  add_col=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "norm = Normalize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "procs = [cat, imp, norm]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DataBunch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "to = TabularPandas(train_df, \n",
    "                   y_block = CategoryBlock(), \n",
    "                   y_names = dep_var,\n",
    "                   splits = RandomSplitter()(range_of(train_df)),\n",
    "                   cat_names = cat_names,\n",
    "                   cont_names = cont_names,\n",
    "                   procs = procs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "dls = to.dataloaders(batch_size=32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Learner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "cbs = [TrackerCallback(monitor=\"roc_auc_score\"), ReduceLROnPlateau(\"roc_auc_score\", patience=3)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "class HypsterBase(object):\n",
    "    def __init__(self): return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "class HypsterTabularLearner(HypsterBase):\n",
    "    def __init__(self, dls, **kwargs):\n",
    "        self.dls = dls\n",
    "        self.__dict__.update(kwargs)\n",
    "        self.func = raw_tabular_learner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "raw_tabular_learner = fastai2.tabular.learner.tabular_learner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "hypster_types = (HypsterBase, HpExpression)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "data_structures = (set, list, dict, L)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "def _contains_hypster(x):\n",
    "    if not isinstance(x, data_structures):\n",
    "        x = [x]\n",
    "    elif isinstance(x, dict):\n",
    "        x = x.values()\n",
    "        \n",
    "    for item in x:\n",
    "        if isinstance(item, data_structures):\n",
    "            if _iterable_contains_hypster(item):\n",
    "                return True\n",
    "        else:\n",
    "            if isinstance(item, hypster_types):\n",
    "                return True\n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "@delegates(raw_tabular_learner)\n",
    "def tabular_learner(dls, **kwargs):\n",
    "    kwargs[\"dls\"] = dls\n",
    "    for key, value in kwargs.items():\n",
    "        if _contains_hypster(value):\n",
    "            return HypsterTabularLearner(**kwargs)\n",
    "    return raw_tabular_learner(**kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "#def tabular_learner():\n",
    "    #put arguments in func definition\n",
    "    #add state to learner = superposition or not\n",
    "    #add trial/study\n",
    "    #check if opt_func is type list\n",
    "        #if so - randomly choose one\n",
    "    #call function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "cbs = [TrackerCallback(monitor=\"roc_auc_score\"), \n",
    "       HpToggle(ReduceLROnPlateau(\"roc_auc_score\", patience=HpInt(\"patience\", 1, 5)))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "cbs = [TrackerCallback(monitor=\"roc_auc_score\"), \n",
    "       ReduceLROnPlateau(\"roc_auc_score\", patience=1)\n",
    "      ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "start_mom = HpFloat(\"start_mom\", 0.85, 0.99)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "learn = tabular_learner(dls=dls, \n",
    "                        metrics=RocAuc(),\n",
    "                        layers=HpList(\"layers\", 1, 3, 50 * HpInt(\"layer_size\", 1, 6), same_value=False),\n",
    "                        opt_func=HpCategorical(\"optimizer\", [Adam, SGD, QHAdam]),\n",
    "                        cbs=cbs,\n",
    "                        moms=(start_mom, start_mom-0.1, start_mom), \n",
    "                        #wd_bn_bias=HpBool(\"wd_bn_bias\"), \n",
    "                        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Optuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "class HypsterExperiment(HypsterBase):\n",
    "    def __init__(self, learner):\n",
    "        self.learner = learner\n",
    "    def fit(self, n_trials):\n",
    "        self.study = study_fit(self.learner, n_trials)        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "from inspect import signature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "def get_func_args(sig):\n",
    "    args = []\n",
    "    for arg, value in sig.parameters.items():\n",
    "        if not \"=\" in str(value):\n",
    "            args.append(arg)\n",
    "    return args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "def pop_move_dict(dict1, keys):\n",
    "    lst = []\n",
    "    for key in list(dict1):\n",
    "        if key in keys:\n",
    "            lst.append(dict1.pop(key))\n",
    "    return lst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "class Objective(object):\n",
    "    def __init__(self, learner):\n",
    "        self.learn = learner\n",
    "    def __call__(self, trial):\n",
    "        learner = deepcopy(self.learn)\n",
    "        func = learner.__dict__.pop(\"func\")\n",
    "        actual_dict = {}\n",
    "        for key, value in learner.__dict__.items():\n",
    "            if _contains_hypster(value):\n",
    "                if isinstance(value, data_structures):\n",
    "                    \n",
    "                else:\n",
    "                    actual_dict[key] = value.sample(trial)\n",
    "            else:\n",
    "                actual_dict[key] = value\n",
    "        \n",
    "        sig = signature(func)\n",
    "        func_args = get_func_args(sig)\n",
    "        args = pop_move_dict(actual_dict, func_args)\n",
    "        print(args)\n",
    "        print(\"\\n\")\n",
    "        print(actual_dict)\n",
    "        actual_learner = func(*args, **actual_dict)\n",
    "        actual_learner.fit_one_cycle(2)\n",
    "        print(actual_learner.cbs)\n",
    "        return actual_learner.cbs[3].best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "def study_fit(learner, n_trials):\n",
    "    optuna.logging.set_verbosity(0)\n",
    "    pruner = optuna.pruners.NopPruner()\n",
    "    study = optuna.create_study(direction=\"maximize\", pruner=pruner)\n",
    "    objective = Objective(learner)\n",
    "    study.optimize(objective, n_trials=n_trials, timeout=600)\n",
    "    return study"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "clf = HypsterExperiment(learn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "clf.fit(n_trials=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "clf.study.trials_dataframe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "#learn = ...\n",
    "hps = HypsterExperiment(learn, learn.fit_one_cycle, n_trials=3) \n",
    "hps.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "import optuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "EPOCHS = 2"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "learn = tabular_learner(dls, metrics=RocAuc(),\n",
    "                        layers=[100, 100], \n",
    "                        opt_func=Adam,\n",
    "                        #emb_szs=[], \n",
    "                        #loss_func,\n",
    "                        #opt_func, \n",
    "                        cbs=cbs,\n",
    "                        #moms=(0.95, 0.85, 0.95),\n",
    "                        #wd=None, wd_bn_bias=False, train_bn=True\n",
    "                       )"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "lr_min, lr_steep = learn.lr_find()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "learn.fit_one_cycle(1, lr_max=lr_steep)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "x = learn.cbs[3]"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "x.best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "def objective(trial):\n",
    "    #Q: How do I define fill value?\n",
    "    cat = Categorify()\n",
    "    fillstraFillStrategy.mode\n",
    "    imp = FillMissing(fill_strategy=fill_strategy,\n",
    "                      add_col=True)\n",
    "\n",
    "    norm = Normalize(mean=5)\n",
    "    procs = [cat, imp, norm]\n",
    "\n",
    "    # DataBunch\n",
    "    to = TabularPandas(train_df, \n",
    "                       y_block = CategoryBlock(), \n",
    "                       y_names = dep_var,\n",
    "                       splits = RandomSplitter()(range_of(train_df)),\n",
    "                       cat_names = cat_names,\n",
    "                       cont_names = cont_names,\n",
    "                       procs = procs)\n",
    "\n",
    "    dls = to.dataloaders(batch_size=512)\n",
    "    \n",
    "    n_layers = trial.suggest_int(\"n_layers\", 2, 5)\n",
    "    layer_sizes = L()\n",
    "    \n",
    "    for i in range(n_layers):\n",
    "        layer_size = trial.suggest_int(\"layer_size_{}\".format(i), 1, 10)\n",
    "        layer_sizes.append(50 * layer_size)\n",
    "\n",
    "    learn = tabular_learner(dls, metrics=RocAuc(),\n",
    "                            layers=layer_sizes, \n",
    "                            #emb_szs=[], \n",
    "                            #loss_func,\n",
    "                            #opt_func, \n",
    "                            cbs=cbs,\n",
    "                            #lr=0.001, moms=(0.95, 0.85, 0.95)\n",
    "                            #wd=None, wd_bn_bias=False, train_bn=True\n",
    "                           )\n",
    "    \n",
    "    learn.fit_flat_cos(EPOCHS)\n",
    "\n",
    "    return learn.cbs[3].best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "optuna.logging.set_verbosity(0)\n",
    "pruner = optuna.pruners.NopPruner()\n",
    "study = optuna.create_study(direction=\"maximize\", pruner=pruner)\n",
    "study.optimize(objective, n_trials=5, timeout=600)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "print(\"Number of finished trials: {}\".format(len(study.trials)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "print(\"Best trial:\")\n",
    "trial = study.best_trial\n",
    "print(\"  Value: {}\".format(trial.value))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "print(\"  Params: \")\n",
    "for key, value in trial.params.items():\n",
    "    print(\"    {}: {}\".format(key, value))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "test_dl = learn.dls.test_dl(test_df.drop(['salary'], axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "probs = learn.get_preds(dl=test_dl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "probs = probs[0][:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "scorer = RocAuc()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "roc_auc_score(test_df[dep_var], probs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Desired API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "fill = HpInt(start_range=1, end_range=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "fill_strategy = HpOptions(\"fill_strategy\", \n",
    "                          [FillStrategy.mode, \n",
    "                           FillStrategy.median, \n",
    "                           FillStrategy.constant(5, fill)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "# or less preferred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "fill_dict = {\"mode\" : FillStrategy.mode, \"median\" : FillStrategy.median, \"constant\" : FillStrategy.constant(5, fill)}\n",
    "fill_strategy = HpOptions(\"fill_strategy\", [\"mode\", \"median\", \"constant\"], fill_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "add_col = HpBool(\"missing_col_bool\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "imp = FillMissing(fill_strategy=fill_strategy, add_col=add_col)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Option A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "norm = Normalize(mean=HpFloat(\"norm_mean\", start=2, end=10, dist=\"uniform\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "procs = [Categorify, imp, HpToggle(norm)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Option B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "norm = HpToggle(Normalize(mean=HpFloat(start=2, end=10, dist=\"uniform\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "procs = [Categorify, imp, norm]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DataBunch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "to = TabularPandas(train_df, \n",
    "                   y_block = CategoryBlock(), \n",
    "                   y_names = dep_var,\n",
    "                   splits = RandomSplitter()(range_of(train_df)),\n",
    "                   cat_names = cat_names,\n",
    "                   cont_names = cont_names,\n",
    "                   procs = procs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Option A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "bs_pow = HpInt(0, 8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "dls = to.dataloaders(batch_size=2**bs_pow)\n",
    "#or\n",
    "dls = to.dataloaders(batch_size=HpConst(2)**bs_pow)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Option B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "dls = to.dataloaders(batch_size=HpBatchSizeFinder(...))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Learner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "from fastai2.metrics import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "cbs = [TrackerCallback(monitor=\"roc_auc_score\")]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### #Layers + Layer Sizes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Option A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "layer_size_hp = HpFuncInt(func=np.multiply, base_value=50, min_int=1, max_int=7)\n",
    "layers = HpVarList(min_len=1, max_len=5, layer_size_hp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Option B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "layer_size_hp = HpInt(min=1, max=7)\n",
    "layers = HpVarList(min_len=1, max_len=5, value=50 * layer_size_hp) \n",
    "#TODO: think of how to distinguish between same value for all items in list and different ones?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "opt_dict = {\"SGD\" : SGD, \"ADAM\" : Adam, \"LAMB\" : fastai2.optimizer.Lamb()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "optimizer = HpOptions([\"SGD\", \"ADAM\", \"LAMB\"], opt_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "if optimizer == \"SGD\":\n",
    "    sqr_mom = Adam()\n",
    "    Lamb(sqr_mom)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Option B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "def opt_name_to_opt(name): if name.containts(\"SGD\") return SGD else Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "optimizer = HpOptions([\"SGD\", \"ADAM\", \"LAMB\"], opt_name_to_opt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Option C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "optimizer = HpOptions([SGD, Adam, Lamb])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Init Learner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "learn = tabular_learner(dls, metrics=RocAuc(),\n",
    "                        layers=layers\n",
    "                        \n",
    "                        #loss_func,\n",
    "                        opt_func = opt_func\n",
    "                        cbs=cbs,\n",
    "                        #moms=(0.95, 0.85, 0.95)\n",
    "                        #wd=None, wd_bn_bias=False, train_bn=True\n",
    "                        #emb_szs=[],\n",
    "                       )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LR Finder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "lr = HpLrFinder(finder_type=\"fastai\", which=\"steep\", kwargs=...)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "learn.fit_flat_cos(3, lr=lr)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}